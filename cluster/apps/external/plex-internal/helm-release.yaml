apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: plex-internal
  namespace: default
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 1.0.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s-charts
        namespace: flux-system
      interval: 5m
  values:
    image:
      repository: ghcr.io/onedr0p/plex-beta
      tag: 1.30.0.6359-1185e28d9@sha256:76141110814f6a754c5bcde7ba9bd790e73578c28f4fb2d520a2981ddb80a351
    controller:
      strategy: Recreate
    podAnnotations:
      backup.velero.io/backup-volumes: config
    env:
      TZ: "UTC"
      ADVERTISE_IP: "https://plex-internal.${SECRET_DOMAIN}:443,http://plex-internal.${SECRET_DOMAIN}:80"
    service:
      main:
        ports:
          http:
            port: 32400
    podSecurityContext:
      runAsUser: 568
      runAsGroup: 568
      fsGroup: 568
      supplementalGroups:
        - 44
        - 109
        - 65539
    ingress:
      main:
        enabled: true
        ingressClassName: nginx
        annotations:
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
        hosts:
          - host: "plex-internal.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: plex-internal
                    port:
                      number: http
        tls:
          - hosts:
              - "plex-internal.${SECRET_DOMAIN}"
            secretName: wildcard-cert-tls

    persistence:
      config:
        enabled: true
        type: custom
        volumeSpec:
          nfs:
            server: 192.168.1.5
            path: "/volume2/pvc/configs/persistence/plex"
      media:
        enabled: true
        type: custom
        volumeSpec:
          nfs:
            server: 192.168.1.3
            path: /volume2/media-sp2
        mountPath: /media
        readOnly: true
      tmp:
        enabled: true
        type: emptyDir
        medium: Memory

    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: feature.node.kubernetes.io/custom-intel-gpu
                  operator: In
                  values:
                    - "true"

    resources:
      requests:
        gpu.intel.com/i915: 1
        cpu: 1000m
        memory: 2Gi
      limits:
        gpu.intel.com/i915: 1
        memory: 10Gi
